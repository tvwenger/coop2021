Initial parameters:
    R0 = 8.18  # kpc
    Zsun = 5.5  # pc
    Usun = 10.6  # km/s
    Vsun = 10.7  # km/s
    Wsun = 7.6  # km/s
    Upec = 6.1  # km/s
    Vpec = -4.3  # km/s
    roll = 0.0  # deg
    a2 = 0.96  # dimensionless
    a3 = 1.62  # dimensionless

==== Testing simulated data ====
=========
Running Bayesian MCMC until convergence w/ A5 priors, cauchy PDF, & reject_method = lnlike
===
Running round 1
===
Using data from pickle file
Number of data points used: 158
Number of distance samples: 100
===
Using prior set A5
+ free Zsun parameter + free roll parameter
Using Cauchy PDF
Using 10 cores, 10 chains, 1000 tunings, and 1000 iterations.
===
Auto-assigning NUTS sampler...
Initializing NUTS using advi...
Convergence achieved at 29200--------------------| 14.60% [29199/200000 15:08<1:28:31 Average Loss = 933.23]
Interrupted at 29,199 [14%]: Average Loss = 983.13
Multiprocess sampling (10 chains in 10 jobs)
NUTS: [roll, Zsun, Vpec, Upec, Wsun, Vsun, Usun, a3, a2, R0]
Sampling 10 chains for 1_000 tune and 1_000 draw iterations (10_000 + 10_000 draws total) took 1313 seconds.
The number of effective samples is smaller than 25% for some parameters.
        mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_mean   ess_sd  ess_bulk  ess_tail  r_hat
R0     8.183  0.026   8.133    8.230      0.000    0.000   13113.0  13113.0   13131.0    8802.0   1.00
Zsun   5.804  9.855 -13.009   23.943      0.086    0.089   13210.0   6192.0   13200.0    7657.0   1.00
Usun  10.907  1.083   8.814   12.872      0.012    0.009    7909.0   7909.0    7908.0    7249.0   1.00
Vsun  17.059  6.100   5.500   28.409      0.178    0.126    1177.0   1177.0    1174.0    1755.0   1.01
Wsun   7.377  0.619   6.239    8.533      0.006    0.004   12587.0  12546.0   12645.0    8456.0   1.00
Upec   5.599  1.361   3.090    8.168      0.016    0.011    7150.0   7075.0    7145.0    6486.0   1.00
Vpec   1.955  5.933  -8.612   13.553      0.172    0.121    1196.0   1196.0    1193.0    1785.0   1.01
roll  -0.002  0.098  -0.176    0.189      0.001    0.001   12856.0   5141.0   12861.0    7986.0   1.00
a2     0.922  0.051   0.826    1.017      0.001    0.001    2766.0   2766.0    2853.0    3185.0   1.00
a3     1.605  0.024   1.563    1.651      0.001    0.000    1242.0   1242.0    1244.0    1897.0   1.01
=== Calculating BIC (A5 priors & 1 MCMC rounds) ===
Number of sources: 158
Likelihood function: cauchy
Number of parameters: 10
Bayesian Information Criterion: 59.165562286023025
===
Executing outlier rejection after round 1
prior_set: A5
like_type: cauchy
num parallax samples: 100
num sources before filtering: 158
Using log-likelihood to reject data
    min predicted ln_mux: -1.742312032275449
    min predicted ln_muy: -2.7396080683015853
    min predicted ln_vlsr: -2.561245686073995
num sources after filtering: 156
===
Running round 2
===
Using data from pickle file
Number of data points used: 156
Number of distance samples: 100
===
Using prior set A5
+ free Zsun parameter + free roll parameter
Using Gaussian PDF
Using 10 cores, 10 chains, 1000 tunings, and 1000 iterations.
===
Auto-assigning NUTS sampler...
Initializing NUTS using advi...
Convergence achieved at 28200--------------------| 14.10% [28192/200000 11:35<1:10:38 Average Loss = 746.02]
Interrupted at 28,199 [14%]: Average Loss = 808.01
Multiprocess sampling (10 chains in 10 jobs)
NUTS: [roll, Zsun, Vpec, Upec, Wsun, Vsun, Usun, a3, a2, R0]
Sampling 10 chains for 1_000 tune and 1_000 draw iterations (10_000 + 10_000 draws total) took 999 seconds.]
The number of effective samples is smaller than 25% for some parameters.
        mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_mean   ess_sd  ess_bulk  ess_tail  r_hat
R0     8.185  0.026   8.135    8.233      0.000    0.000   13215.0  13215.0   13206.0    8530.0   1.00
Zsun   6.505  9.973 -11.709   25.632      0.090    0.096   12370.0   5411.0   12386.0    6527.0   1.00
Usun  10.694  1.040   8.782   12.675      0.012    0.008    7595.0   7591.0    7592.0    7007.0   1.00
Vsun  16.778  5.742   6.262   27.698      0.154    0.111    1386.0   1345.0    1382.0    1576.0   1.01
Wsun   7.583  0.565   6.564    8.694      0.005    0.004   13156.0  13048.0   13157.0    8308.0   1.00
Upec   5.285  1.258   3.038    7.678      0.015    0.010    7399.0   7340.0    7399.0    7023.0   1.00
Vpec   1.966  5.568  -8.082   12.704      0.149    0.111    1390.0   1251.0    1387.0    1546.0   1.01
roll   0.002  0.098  -0.179    0.186      0.001    0.001   13145.0   4967.0   13164.0    8009.0   1.00
a2     0.939  0.045   0.856    1.022      0.001    0.001    2615.0   2615.0    2766.0    3567.0   1.00
a3     1.608  0.022   1.567    1.651      0.001    0.000    1484.0   1484.0    1489.0    1901.0   1.01
=== Calculating BIC (A5 priors & 2 MCMC rounds) ===
Number of sources: 156
Likelihood function: gauss
Number of parameters: 10
Bayesian Information Criterion: 56.777886863636155
===
Executing outlier rejection after round 2
prior_set: A5
like_type: gauss
num parallax samples: 100
num sources before filtering: 156
Using log-likelihood to reject data
    min predicted ln_mux: -3.3215830837151303
    min predicted ln_muy: -4.4446305241683906
    min predicted ln_vlsr: -3.383760229634447
num sources after filtering: 156
No more outliers rejected after round 2. Exiting
===
2 Bayesian MCMC runs complete
=========


==========================================================================================
 The following runs have the wrong weights
 since I passed plx instead of dist into get_weights() function
 (but the results are similar)
==========================================================================================
Initial parameters:
    R0 = 8.15  # kpc
    Usun = 10.6  # km/s
    Vsun = 10.7  # km/s
    Wsun = 7.6  # km/s
    Upec = 6.1  # km/s
    Vpec = -4.3  # km/s
    a2 = 0.96  # dimensionless
    a3 = 1.62  # dimensionless


==== Testing simulated data with DISTANCES (i.e. using generate_dists function) ====
=========
Queueing 2 Bayesian MCMC rounds w/ A5 priors, cauchy PDF, & reject_method = lnlike
===
Running round 1
===
Using data from pickle file
Number of data points used: 158
Number of distance samples: 100
===
Using prior set A5
Using Cauchy PDF
Using 2 cores, 2 chains, 500 tunings, and 500 iterations.
===
Auto-assigning NUTS sampler...
Initializing NUTS using advi...
Convergence achieved at 10200------------------------------------------------------------------------| 5.10% [10198/200000 05:55<1:50:11 Average Loss = 1,401.7]
Interrupted at 10,199 [5%]: Average Loss = 1,410.1
Multiprocess sampling (2 chains in 2 jobs)
NUTS: [Vpec, Upec, Wsun, Vsun, Usun, a3, a2, R0]
Sampling 2 chains for 500 tune and 500 draw iterations (1_000 + 1_000 draws total) took 803 seconds.00% [2000/2000 13:20<00:00 Sampling 2 chains, 0 divergences]
The estimated number of effective samples is smaller than 200 for some parameters.
        mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_mean  ess_sd  ess_bulk  ess_tail  r_hat
R0     8.245  0.200   7.863    8.609      0.006    0.004    1060.0  1057.0    1066.0     819.0   1.00
Usun  10.904  1.100   8.934   12.919      0.037    0.026     887.0   887.0     886.0     912.0   1.00
Vsun  12.172  6.711  -0.682   23.489      0.628    0.445     114.0   114.0     113.0     195.0   1.03
Wsun   7.385  0.824   5.911    8.930      0.022    0.015    1430.0  1416.0    1441.0     848.0   1.00
Upec   6.649  1.353   4.354    9.389      0.047    0.033     846.0   839.0     846.0     725.0   1.00
Vpec  -2.654  6.649 -15.659    8.258      0.623    0.441     114.0   114.0     113.0     224.0   1.03
a2     0.989  0.080   0.837    1.128      0.003    0.002     754.0   754.0     755.0     564.0   1.00
a3     1.622  0.029   1.572    1.680      0.002    0.001     251.0   251.0     252.0     342.0   1.02
===
Executing outlier rejection after round 1
prior_set: A5
like_type: cauchy
num parallax samples: 100
num sources before filtering: 158
Using log-likelihood to reject data
        min predicted ln_mux: -0.012314499466709705
        min predicted ln_muy: -0.014398998763900606
        min predicted ln_vlsr: -1.9195427670835448
num sources after filtering: 158
===
Running round 2
===
Using data from pickle file
Number of data points used: 158
Number of distance samples: 100
===
Using prior set A5
Using Gaussian PDF
Using 2 cores, 2 chains, 500 tunings, and 500 iterations.
===
Auto-assigning NUTS sampler...
Initializing NUTS using advi...
Convergence achieved at 10100-------------------------------------------------------------------------| 5.05% [10095/200000 04:43<1:28:54 Average Loss = 1,217]]
Interrupted at 10,099 [5%]: Average Loss = 1,226.7
Multiprocess sampling (2 chains in 2 jobs)
NUTS: [Vpec, Upec, Wsun, Vsun, Usun, a3, a2, R0]
Sampling 2 chains for 500 tune and 500 draw iterations (1_000 + 1_000 draws total) took 645 seconds.00% [2000/2000 10:42<00:00 Sampling 2 chains, 0 divergences]
The estimated number of effective samples is smaller than 200 for some parameters.
        mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_mean  ess_sd  ess_bulk  ess_tail  r_hat
R0     8.241  0.190   7.888    8.601      0.006    0.005     881.0   881.0     881.0     808.0   1.00
Usun  10.899  1.178   8.827   13.207      0.042    0.030     770.0   769.0     772.0     556.0   1.00
Vsun  13.262  6.272   0.433   23.223      0.502    0.401     156.0   123.0     157.0     155.0   1.01
Wsun   7.329  0.887   5.558    9.037      0.023    0.016    1481.0  1451.0    1454.0     743.0   1.00
Upec   6.710  1.513   3.688    9.463      0.052    0.037     850.0   818.0     851.0     536.0   1.00
Vpec  -1.500  6.213 -13.377    9.112      0.498    0.353     155.0   155.0     156.0     143.0   1.01
a2     0.988  0.082   0.820    1.126      0.003    0.002     789.0   789.0     784.0     627.0   1.00
a3     1.616  0.028   1.568    1.673      0.002    0.001     288.0   288.0     287.0     470.0   1.01
===
2 Bayesian MCMC runs complete
=========


==== Testing simulated data with PARALLAXES (i.e. generating random parallaxes) ====
=========
Queueing 2 Bayesian MCMC rounds w/ A5 priors, cauchy PDF, & reject_method = lnlike
===
Running round 1
===
Using data from pickle file
Number of data points used: 158
===
Number of plx samples: 100
Number of plx <= 0 replaced: 0
===
Using prior set A5
Using Cauchy PDF
Using 2 cores, 2 chains, 500 tunings, and 500 iterations.
===
Auto-assigning NUTS sampler...
Initializing NUTS using advi...
Convergence achieved at 10100------------------------------------------------------------------------| 5.05% [10094/200000 04:57<1:33:14 Average Loss = 1,399.5]
Interrupted at 10,099 [5%]: Average Loss = 1,408.7
Multiprocess sampling (2 chains in 2 jobs)
NUTS: [Vpec, Upec, Wsun, Vsun, Usun, a3, a2, R0]
Sampling 2 chains for 500 tune and 500 draw iterations (1_000 + 1_000 draws total) took 598 seconds.00% [2000/2000 09:55<00:00 Sampling 2 chains, 0 divergences]
The estimated number of effective samples is smaller than 200 for some parameters.
        mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_mean  ess_sd  ess_bulk  ess_tail  r_hat
R0     8.033  0.165   7.685    8.310      0.005    0.004     988.0   988.0     985.0     594.0   1.00
Usun  11.024  1.079   8.937   12.970      0.041    0.030     676.0   669.0     670.0     709.0   1.00
Vsun  12.926  6.204   2.808   26.359      0.537    0.380     134.0   134.0     140.0     122.0   1.01
Wsun   7.361  0.834   5.694    8.810      0.025    0.018    1107.0  1107.0    1099.0     694.0   1.01
Upec   6.558  1.309   3.866    8.760      0.050    0.035     688.0   688.0     688.0     817.0   1.00
Vpec  -1.814  6.144 -12.964   10.595      0.543    0.385     128.0   128.0     131.0     120.0   1.01
a2     0.966  0.078   0.821    1.108      0.003    0.002     837.0   837.0     834.0     675.0   1.01
a3     1.611  0.027   1.556    1.655      0.002    0.001     281.0   281.0     281.0     516.0   1.00
===
Executing outlier rejection after round 1
prior_set: A5
like_type: cauchy
num parallax samples: 100
num sources before filtering: 158
Using log-likelihood to reject data
    min predicted ln_mux: -0.01653732280196729
    min predicted ln_muy: -0.012943753481678089
    min predicted ln_vlsr: -2.2326209699778006
num sources after filtering: 157
===
Running round 2
===
Using data from pickle file
Number of data points used: 157
===
Number of plx samples: 100
Number of plx <= 0 replaced: 0
===
Using prior set A5
Using Gaussian PDF
Using 2 cores, 2 chains, 500 tunings, and 500 iterations.
===
Auto-assigning NUTS sampler...
Initializing NUTS using advi...
Convergence achieved at 10600------------------------------------------------------------------------| 5.30% [10598/200000 04:52<1:27:10 Average Loss = 1,204.2]
Interrupted at 10,599 [5%]: Average Loss = 1,214.1
Multiprocess sampling (2 chains in 2 jobs)
NUTS: [Vpec, Upec, Wsun, Vsun, Usun, a3, a2, R0]
Sampling 2 chains for 500 tune and 500 draw iterations (1_000 + 1_000 draws total) took 591 seconds.00% [2000/2000 09:48<00:00 Sampling 2 chains, 0 divergences]
The number of effective samples is smaller than 25% for some parameters.
        mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_mean  ess_sd  ess_bulk  ess_tail  r_hat
R0     7.968  0.180   7.634    8.311      0.006    0.004     840.0   837.0     841.0     800.0    1.0
Usun  10.919  1.120   8.675   12.893      0.038    0.027     854.0   854.0     861.0     766.0    1.0
Vsun  11.924  6.153   0.502   23.429      0.431    0.305     204.0   204.0     201.0     215.0    1.0
Wsun   7.343  0.831   5.927    9.056      0.026    0.018    1038.0  1033.0    1045.0     782.0    1.0
Upec   6.440  1.428   3.914    9.072      0.055    0.039     664.0   664.0     664.0     770.0    1.0
Vpec  -2.746  6.115 -14.265    8.184      0.427    0.303     205.0   205.0     202.0     206.0    1.0
a2     0.967  0.084   0.808    1.122      0.003    0.002     639.0   639.0     637.0     569.0    1.0
a3     1.611  0.027   1.563    1.665      0.001    0.001     399.0   399.0     397.0     456.0    1.0
===
2 Bayesian MCMC runs complete
=========


==== Testing simulated data with DISTANCES (now using generate_dists function  multiplied w/ sigma^2) ====
=========
Queueing 2 Bayesian MCMC rounds w/ A5 priors, cauchy PDF, & reject_method = lnlike
===
Running round 1
===
Using data from pickle file
Number of data points used: 158
Number of distance samples: 100
===
Using prior set A5
Using Cauchy PDF
Using 2 cores, 2 chains, 500 tunings, and 500 iterations.
===
Auto-assigning NUTS sampler...
Initializing NUTS using advi...
Convergence achieved at 9100--------------------------------------------------------------------------| 4.55% [9095/200000 05:04<1:46:21 Average Loss = 1,402.4]
Interrupted at 9,099 [4%]: Average Loss = 1,411.2
Multiprocess sampling (2 chains in 2 jobs)
NUTS: [Vpec, Upec, Wsun, Vsun, Usun, a3, a2, R0]
Sampling 2 chains for 500 tune and 500 draw iterations (1_000 + 1_000 draws total) took 770 seconds.00% [2000/2000 12:47<00:00 Sampling 2 chains, 0 divergences]
The estimated number of effective samples is smaller than 200 for some parameters.
        mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_mean  ess_sd  ess_bulk  ess_tail  r_hat
R0     8.217  0.192   7.828    8.571      0.006    0.004    1003.0  1003.0    1004.0     795.0   1.00
Usun  10.943  1.132   8.896   13.038      0.050    0.035     510.0   510.0     506.0     648.0   1.01
Vsun  13.042  6.636   0.319   24.601      0.591    0.419     126.0   126.0     128.0     130.0   1.04
Wsun   7.350  0.811   5.975    8.858      0.023    0.016    1243.0  1243.0    1232.0     809.0   1.00
Upec   6.634  1.430   3.989    9.335      0.079    0.056     324.0   324.0     327.0     521.0   1.02
Vpec  -1.801  6.578 -14.921    8.994      0.582    0.475     128.0    96.0     129.0     126.0   1.04
a2     0.982  0.087   0.817    1.151      0.005    0.004     287.0   287.0     374.0     200.0   1.02
a3     1.617  0.031   1.553    1.671      0.002    0.002     184.0   184.0     193.0     238.0   1.02
===
Executing outlier rejection after round 1
prior_set: A5
like_type: cauchy
num parallax samples: 100
num sources before filtering: 158
Using log-likelihood to reject data
    min predicted ln_mux: -0.014208162785057543
    min predicted ln_muy: -0.016414333152256266
    min predicted ln_vlsr: -2.437704825030912
num sources after filtering: 156
===
Running round 2
===
Using data from pickle file
Number of data points used: 156
Number of distance samples: 100
===
Using prior set A5
Using Gaussian PDF
Using 2 cores, 2 chains, 500 tunings, and 500 iterations.
===
Auto-assigning NUTS sampler...
Initializing NUTS using advi...
Convergence achieved at 10000-------------------------------------------------------------------------| 5.00% [9997/200000 04:24<1:23:56 Average Loss = 1,194.2]
Interrupted at 9,999 [4%]: Average Loss = 1,204
Multiprocess sampling (2 chains in 2 jobs)
NUTS: [Vpec, Upec, Wsun, Vsun, Usun, a3, a2, R0]
Sampling 2 chains for 500 tune and 500 draw iterations (1_000 + 1_000 draws total) took 650 seconds.00% [2000/2000 10:47<00:00 Sampling 2 chains, 0 divergences]
The estimated number of effective samples is smaller than 200 for some parameters.
        mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_mean  ess_sd  ess_bulk  ess_tail  r_hat
R0     8.206  0.184   7.855    8.545      0.006    0.004     923.0   923.0     926.0     619.0   1.00
Usun  11.041  1.152   8.680   12.900      0.041    0.029     773.0   769.0     765.0     609.0   1.00
Vsun  12.323  7.376  -0.583   27.129      0.652    0.473     128.0   122.0     129.0     199.0   1.02
Wsun   7.309  0.935   5.446    8.940      0.026    0.018    1292.0  1292.0    1307.0     537.0   1.01
Upec   6.814  1.513   4.207    9.697      0.058    0.041     687.0   666.0     682.0     666.0   1.00
Vpec  -2.433  7.330 -15.326   12.343      0.646    0.458     129.0   129.0     129.0     196.0   1.02
a2     0.982  0.089   0.818    1.152      0.004    0.003     424.0   424.0     480.0     211.0   1.00
a3     1.618  0.031   1.561    1.673      0.002    0.001     212.0   212.0     212.0     344.0   1.01
===
2 Bayesian MCMC runs complete
=========


==== Testing simulated data with DISTANCES (i.e. using generate_dists function) ====
=========
Queueing 1 Bayesian MCMC rounds w/ A5 priors, cauchy PDF
===
Running round 1
===
Using data from pickle file
Number of data points used: 158
Number of distance samples: 100
===
Using prior set A5
Using Cauchy PDF
Using 2 cores, 2 chains, 2000 tunings, and 2000 iterations.
===
Auto-assigning NUTS sampler...
Initializing NUTS using advi...
Convergence achieved at 10200------------------------------------------------------------------------| 5.10% [10197/200000 06:16<1:56:40 Average Loss = 1,401.6]
Interrupted at 10,199 [5%]: Average Loss = 1,409.8
Multiprocess sampling (2 chains in 2 jobs)
NUTS: [Vpec, Upec, Wsun, Vsun, Usun, a3, a2, R0]
Sampling 2 chains for 2_000 tune and 2_000 draw iterations (4_000 + 4_000 draws total) took 3389 seconds.8000/8000 56:28<00:00 Sampling 2 chains, 0 divergences]
The number of effective samples is smaller than 25% for some parameters.
        mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_mean  ess_sd  ess_bulk  ess_tail  r_hat
R0     8.223  0.187   7.870    8.568      0.003    0.002    3471.0  3471.0    3481.0    3290.0   1.00
Usun  10.991  1.154   8.785   13.039      0.021    0.015    2998.0  2960.0    3001.0    2255.0   1.00
Vsun  12.451  6.753   0.789   26.221      0.303    0.215     496.0   496.0     495.0     518.0   1.01
Wsun   7.376  0.867   5.708    8.977      0.013    0.009    4536.0  4466.0    4531.0    2733.0   1.00
Upec   6.692  1.448   3.846    9.233      0.027    0.020    2790.0  2732.0    2794.0    2247.0   1.00
Vpec  -2.386  6.689 -14.547   10.540      0.299    0.215     499.0   487.0     500.0     489.0   1.01
a2     0.985  0.080   0.822    1.126      0.002    0.001    2756.0  2756.0    2749.0    1997.0   1.00
a3     1.619  0.029   1.567    1.675      0.001    0.001     921.0   921.0     924.0    1258.0   1.00
===
1 Bayesian MCMC runs complete
=========

==== Testing simulated data with DISTANCES (i.e. using generate_dists function) ====
=========
Queueing 2 Bayesian MCMC rounds w/ A5 priors, cauchy PDF, & reject_method = lnlike
===
Running round 1
===
Using data from pickle file
Number of data points used: 158
Number of distance samples: 100
===
Using prior set A5
Using Cauchy PDF
Using 10 cores, 10 chains, 1000 tunings, and 1000 iterations.
===
Auto-assigning NUTS sampler...
Initializing NUTS using advi...
Convergence achieved at 10200-----------------------| 5.10% [10199/200000 04:54<1:31:28 Average Loss = 1,411]1]
Interrupted at 10,199 [5%]: Average Loss = 1,419.1
Multiprocess sampling (10 chains in 10 jobs)
NUTS: [Vpec, Upec, Wsun, Vsun, Usun, a3, a2, R0]
Sampling 10 chains for 1_000 tune and 1_000 draw iterations (10_000 + 10_000 draws total) took 1671 seconds.es]
The number of effective samples is smaller than 25% for some parameters.
        mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_mean   ess_sd  ess_bulk  ess_tail  r_hat
R0     8.289  0.198   7.918    8.658      0.002    0.001    9155.0   9147.0    9173.0    8191.0   1.00
Usun  10.988  1.152   8.914   13.188      0.013    0.009    7795.0   7722.0    7787.0    6506.0   1.00
Vsun  13.375  6.805   0.567   26.051      0.186    0.131    1340.0   1340.0    1337.0    1567.0   1.01
Wsun   7.623  0.848   6.015    9.227      0.007    0.005   12964.0  12960.0   12975.0    7301.0   1.00
Upec   6.610  1.429   4.032    9.408      0.016    0.012    7851.0   7688.0    7850.0    6735.0   1.00
Vpec  -1.556  6.775 -14.137   11.208      0.185    0.131    1342.0   1342.0    1339.0    1550.0   1.01
a2     0.981  0.081   0.827    1.132      0.001    0.001    6990.0   6990.0    7034.0    5107.0   1.00
a3     1.622  0.029   1.569    1.678      0.001    0.000    2734.0   2734.0    2735.0    4325.0   1.00
===
Executing outlier rejection after round 1
prior_set: A5
like_type: cauchy
num parallax samples: 100
num sources before filtering: 158
Using log-likelihood to reject data
    min predicted ln_mux: -0.3592682787798831
    min predicted ln_muy: -0.18732783212910237
    min predicted ln_vlsr: -2.810271209322346
num sources after filtering: 156
===
Running round 2
===
Using data from pickle file
Number of data points used: 156
Number of distance samples: 100
===
Using prior set A5
Using Gaussian PDF
Using 10 cores, 10 chains, 1000 tunings, and 1000 iterations.
===
Auto-assigning NUTS sampler...
Initializing NUTS using advi...
Convergence achieved at 10700-----------------------| 5.35% [10693/200000 04:01<1:11:18 Average Loss = 1,201.1]
Interrupted at 10,699 [5%]: Average Loss = 1,210.5
Multiprocess sampling (10 chains in 10 jobs)
NUTS: [Vpec, Upec, Wsun, Vsun, Usun, a3, a2, R0]
Sampling 10 chains for 1_000 tune and 1_000 draw iterations (10_000 + 10_000 draws total) took 1100 seconds.es]
The number of effective samples is smaller than 25% for some parameters.
        mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_mean   ess_sd  ess_bulk  ess_tail  r_hat
R0     8.261  0.182   7.913    8.598      0.002    0.001    9511.0   9511.0    9528.0    7379.0   1.00
Usun  11.020  1.150   8.836   13.154      0.013    0.009    7494.0   7494.0    7507.0    6288.0   1.00
Vsun  13.128  7.155  -0.775   25.769      0.199    0.143    1297.0   1258.0    1330.0    1393.0   1.01
Wsun   7.569  0.870   5.985    9.207      0.008    0.006   12222.0  12096.0   12241.0    7314.0   1.00
Upec   6.636  1.495   3.826    9.394      0.017    0.012    7473.0   7392.0    7485.0    6466.0   1.00
Vpec  -1.766  7.128 -15.111   11.387      0.199    0.160    1286.0    990.0    1319.0    1401.0   1.01
a2     0.976  0.081   0.821    1.123      0.001    0.001    6476.0   6476.0    6470.0    5045.0   1.00
a3     1.622  0.029   1.569    1.679      0.001    0.000    2203.0   2203.0    2212.0    2824.0   1.00
===
2 Bayesian MCMC runs complete
=========
